# ğŸ“š Book Recommender System

Welcome to the **Book Recommender System**! This project is a Streamlit-based application that provides personalized book recommendations using a k-Nearest Neighbors (kNN) model, and a collaborative filtering approach via SVD.

---

## ğŸ” Features

### ğŸ”¢ General Statistics
- Displays the total number of books and users in the dataset.

### ğŸ® Popular Books
- Shows the most popular books based on the number of ratings.

### ğŸŒŸ Top-Rated Books
- Highlights the top-rated books in the dataset.

### ğŸ” Recommendations
- Provides book recommendations based on user selection.
- Allows users to rate recommendations and save their feedback.

### ğŸ•µï¸â€â™‚ï¸ Advanced Search
- Search for books by keywords.

### ğŸŒ Random Book Discovery
- Discover a random book from the dataset.

### ğŸ¨ Visualizations
- View distributions of ratings and user interactions with books.

---

## ğŸ’ª Technologies Used

- **Streamlit**: For building the web-based user interface.
- **scikit-learn**: For implementing the kNN recommendation algorithm.
- **pandas**: For data manipulation.
- **plotly**: For creating interactive visualizations.
- **pickle**: For saving and loading the pre-trained model and datasets.
- **SVD (Singular Value Decomposition)**: For collaborative filtering-based recommendations.

---

## ğŸš€ How to Run the Application

### Prerequisites

- Python 3.9 or later
- Required Python libraries (listed in `requirements.txt`):

### Steps to Run

1. Clone the repository:
   ```bash
   git clone https://github.com/your-username/book-recommender-system.git
   cd book-recommender-system
   ```

2. Install the dependencies:
   ```bash
   pip install -r requirements.txt
   ```

3. Place the required data and model files in the `artifacts/` directory:
   - `knn_model.pkl`
   - `svd_model.pkl`
   - `book_titles.pkl`
   - `book_df.pkl`

4. Run the Streamlit app:
   ```bash
   streamlit run app.py
   ```

5. Open your web browser and navigate to `http://localhost:8501`.

---

## ğŸŒ„ File Structure

```
book-recommender-system/
â”œâ”€â”€ app.py                        # Main application script  
â”œâ”€â”€ utils.py                      # Functions library
â”œâ”€â”€ tabs/                         # Tabs functions library
â”‚   â”œâ”€â”€ tab0.py
â”‚   â”œâ”€â”€ tab1.py
â”‚   â”œâ”€â”€ tab2.py
â”‚   â”œâ”€â”€ tab3.py
â”‚   â”œâ”€â”€ tab4.py
â”‚   â”œâ”€â”€ tab5.py
â”‚   â””â”€â”€ tab6.py
â”œâ”€â”€ artifacts/                    # Contains model and dataset files
â”‚   â”œâ”€â”€ svd_model.pkl             # Trained SVD model
â”‚   â”œâ”€â”€ knn_model.pkl            # Trained KNN model
â”‚   â”œâ”€â”€ book_df.pkl              # Book DataFrame
â”‚   â””â”€â”€ book_titles.pkl          # Titles of the books
â”œâ”€â”€ data/                         # Raw and cleaned datasets
â”‚   â”œâ”€â”€ dataset.csv              # Raw dataset with book info
â”‚   â”œâ”€â”€ Ratings.csv              # Ratings data
â”‚   â”œâ”€â”€ dataset_with_details.csv # Extended dataset
â”‚   â”œâ”€â”€ cleaned_data.csv         # Preprocessed dataset
â”‚   â”œâ”€â”€ Users.csv                # User data
â”‚   â””â”€â”€ Books.csv                # Book data
â”œâ”€â”€ scrapper/                     # Scraping scripts
â”‚   â”œâ”€â”€ scrapper.py              # Main scraping script
â”‚   â””â”€â”€ scrapper_cache_check.py  # Script to verify cached data
â”œâ”€â”€ notebooks/                    # Jupyter notebooks for model training and analysis
â”‚   â”œâ”€â”€ base.ipynb               # Basic EDA notebook
â”œâ”€â”€ Dockerfile                    # Docker configuration file
â”œâ”€â”€ train.py                      # Script for training the recommendation model
â”œâ”€â”€ requirements.txt              # Dependencies for the project
â”œâ”€â”€ runtime.txt                   # Specifies Python version for deployment
â”œâ”€â”€ README.md                     # Project documentation
â”œâ”€â”€ LICENSE                       # License information
â””â”€â”€ .gitignore                    # Git ignore file
```

### Description of Key Files

- **artifacts/**: Contains all the generated artifacts from the training process, including the trained models and processed data.
- **data/**: Directory for raw and cleaned datasets.
- **scrapper/**: Contains the scraping scripts used to collect book and user data.
- **notebooks/**: Jupyter notebooks for exploratory data analysis (EDA) and model training.
- **Dockerfile**: Used for containerizing the application.
- **app.py**: The main application file for deploying the recommendation engine.
- **requirements.txt**: Lists all the Python dependencies required for the project.
- **runtime.txt**: Specifies the runtime environment for deployment (e.g., Python version).
- **train.py**: A standalone Python script for training the recommendation engine model.

---

## ğŸ¨ Screenshots

### ğŸŒ Home Page
![Home Page](https://via.placeholder.com/600x300)

### ğŸ” Recommendations
![Recommendations](https://via.placeholder.com/600x300)

### ğŸ¨ Visualizations
![Visualizations](https://via.placeholder.com/600x300)

---

## âš–ï¸ License

This project is licensed under the MIT License. See the `LICENSE` file for details.

---

Thank you for exploring the Book Recommender System! ğŸš€